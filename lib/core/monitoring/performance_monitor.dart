/// Unified Performance Monitoring System
///
/// ë°±ê·¸ë¼ìš´ë“œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ - Observer íŒ¨í„´ê³¼ ë‹¨ìˆœí™”ëœ ìˆ˜ì§‘ ë°©ì‹ì„ ê²°í•©
/// DatabaseMetrics(ì¿¼ë¦¬ì‹œê°„, ìºì‹œíˆíŠ¸ìœ¨), APIMetrics(ì‘ë‹µì‹œê°„, ì—ëŸ¬ìœ¨),
/// UIMetrics(FPS, ë¹Œë“œì‹œê°„), ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ CircularBuffer, ë°°ì¹˜ ì „ì†¡ì„ ì œê³µí•©ë‹ˆë‹¤.
///
/// Task 8.11: ë°±ê·¸ë¼ìš´ë“œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì‹œìŠ¤í…œ êµ¬í˜„
/// - ì‚¬ìš©ì ì˜í–¥ ì—†ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì•± ì„±ëŠ¥ ë°ì´í„° ìˆ˜ì§‘
/// - Vercel Analyticsë¡œ ë°°ì¹˜ ì „ì†¡ (5ë¶„ë§ˆë‹¤)
/// - ìµœì†Œ ì˜¤ë²„í—¤ë“œ (ìˆœí™˜ ë²„í¼, ë©”ëª¨ë¦¬ 1MB ì œí•œ)
/// - í”„ë¼ì´ë²„ì‹œ ë³´í˜¸ (ìµëª…í™”ëœ ì„±ëŠ¥ ë°ì´í„°ë§Œ ìˆ˜ì§‘)
///
/// ì‚¬ìš©ë²•:
/// ```dart
/// final collector = MetricCollector.instance;
/// await collector.initialize();
///
/// // ë°ì´í„°ë² ì´ìŠ¤ ë©”íŠ¸ë¦­ ë˜í•‘
/// final result = await collector.measureDatabaseQuery('user_login', () async => loginUser());
///
/// // API ëª¨ë‹ˆí„°ë§ (Dio interceptor ìë™ ì„¤ì •)
/// final dio = Dio();
/// dio.interceptors.add(collector.dioInterceptor);
///
/// // ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ê¸°ë¡
/// collector.recordCustomMetric(name: 'image_process', value: 150.0, type: MetricType.ui);
/// ```
library;

import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:math';
import 'package:flutter/foundation.dart';
import 'package:flutter/scheduler.dart';
import 'package:flutter/widgets.dart';
import 'package:http/http.dart' as http;
import 'package:dio/dio.dart';

// ============================================================================
// í•µì‹¬ ì¸í„°í˜ì´ìŠ¤ ë° ê¸°ë³¸ í´ë˜ìŠ¤
// ============================================================================

/// ì„±ëŠ¥ ê´€ì°°ì ì¸í„°í˜ì´ìŠ¤ - Observer íŒ¨í„´ êµ¬í˜„
abstract class PerformanceObserver {
  /// ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ì‹œ í˜¸ì¶œë©ë‹ˆë‹¤
  void onMetricUpdated(PerformanceMetric metric, MetricData data);

  /// ì„ê³„ê°’ ì´ˆê³¼ ì‹œ í˜¸ì¶œë©ë‹ˆë‹¤
  void onThresholdExceeded(
    PerformanceMetric metric,
    MetricData data,
    MetricThreshold threshold,
  );

  /// ì—ëŸ¬ ë°œìƒ ì‹œ í˜¸ì¶œë©ë‹ˆë‹¤
  void onError(PerformanceMetric metric, String error, StackTrace? stackTrace);
}

/// ë©”íŠ¸ë¦­ ì„ê³„ê°’ ì„¤ì •
class MetricThreshold {
  final String name;
  final double warningLevel;
  final double criticalLevel;
  final Duration checkInterval;
  final bool enabled;

  const MetricThreshold({
    required this.name,
    required this.warningLevel,
    required this.criticalLevel,
    this.checkInterval = const Duration(seconds: 30),
    this.enabled = true,
  });

  /// ê°’ì´ ì„ê³„ê°’ì„ ì´ˆê³¼í•˜ëŠ”ì§€ í™•ì¸
  AlertSeverity? checkThreshold(double value) {
    if (!enabled) return null;
    if (value >= criticalLevel) return AlertSeverity.critical;
    if (value >= warningLevel) return AlertSeverity.warning;
    return null;
  }

  Map<String, dynamic> toJson() => {
    'name': name,
    'warningLevel': warningLevel,
    'criticalLevel': criticalLevel,
    'checkInterval': checkInterval.inMilliseconds,
    'enabled': enabled,
  };
}

/// ì•Œë¦¼ ì‹¬ê°ë„ ë ˆë²¨
enum AlertSeverity { info, warning, critical }

/// ë©”íŠ¸ë¦­ ë°ì´í„° í¬ì¸íŠ¸
class MetricData {
  final String metricName;
  final double value;
  final Map<String, dynamic> metadata;
  final DateTime timestamp;
  final String? unit;

  MetricData({
    required this.metricName,
    required this.value,
    this.metadata = const {},
    DateTime? timestamp,
    this.unit,
  }) : timestamp = timestamp ?? DateTime.now();

  Map<String, dynamic> toJson() => {
    'metricName': metricName,
    'value': value,
    'metadata': metadata,
    'timestamp': timestamp.toIso8601String(),
    'unit': unit,
  };

  factory MetricData.fromJson(Map<String, dynamic> json) => MetricData(
    metricName: json['metricName'],
    value: json['value'],
    metadata: Map<String, dynamic>.from(json['metadata'] ?? {}),
    timestamp: DateTime.parse(json['timestamp']),
    unit: json['unit'],
  );
}

/// ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë³¸ í´ë˜ìŠ¤
abstract class PerformanceMetric {
  final String name;
  final Map<String, MetricThreshold> _thresholds = {};
  final StreamController<MetricData> _streamController =
      StreamController<MetricData>.broadcast();
  final List<MetricData> _history = [];
  final int maxHistorySize;

  PerformanceMetric({required this.name, this.maxHistorySize = 1000});

  /// ë©”íŠ¸ë¦­ ë°ì´í„° ìŠ¤íŠ¸ë¦¼
  Stream<MetricData> get stream => _streamController.stream;

  /// ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬
  List<MetricData> get history => List.unmodifiable(_history);

  /// ìµœê·¼ ë©”íŠ¸ë¦­ ê°’
  MetricData? get latest => _history.isEmpty ? null : _history.last;

  /// ì„ê³„ê°’ ì„¤ì •
  void setThreshold(MetricThreshold threshold) {
    _thresholds[threshold.name] = threshold;
  }

  /// ì„ê³„ê°’ ì œê±°
  void removeThreshold(String name) {
    _thresholds.remove(name);
  }

  /// ëª¨ë“  ì„ê³„ê°’ ê°€ì ¸ì˜¤ê¸°
  Map<String, MetricThreshold> get thresholds => Map.unmodifiable(_thresholds);

  /// ë©”íŠ¸ë¦­ ë°ì´í„° ê¸°ë¡
  void recordData(MetricData data) {
    _history.add(data);

    // íˆìŠ¤í† ë¦¬ í¬ê¸° ê´€ë¦¬
    if (_history.length > maxHistorySize) {
      _history.removeAt(0);
    }

    // ìŠ¤íŠ¸ë¦¼ì— ë°ì´í„° ì „ì†¡
    _streamController.add(data);

    // MetricCollectorì— ì•Œë¦¼
    MetricCollector.instance._notifyObservers(this, data);

    // ì„ê³„ê°’ ê²€ì‚¬
    _checkThresholds(data);
  }

  /// ì„ê³„ê°’ ê²€ì‚¬
  void _checkThresholds(MetricData data) {
    for (final threshold in _thresholds.values) {
      final severity = threshold.checkThreshold(data.value);
      if (severity != null) {
        MetricCollector.instance._notifyThresholdExceeded(
          this,
          data,
          threshold,
        );
        ThresholdAlert.instance.triggerAlert(this, data, threshold, severity);
      }
    }
  }

  /// í†µê³„ ê³„ì‚°
  Map<String, double> getStatistics({Duration? period}) {
    final relevantData = period != null
        ? _history
              .where(
                (data) => DateTime.now().difference(data.timestamp) <= period,
              )
              .toList()
        : _history;

    if (relevantData.isEmpty) {
      return {'min': 0.0, 'max': 0.0, 'avg': 0.0, 'median': 0.0, 'count': 0.0};
    }

    final values = relevantData.map((d) => d.value).toList()..sort();
    final count = values.length;
    final sum = values.reduce((a, b) => a + b);

    return {
      'min': values.first,
      'max': values.last,
      'avg': sum / count,
      'median': count % 2 == 0
          ? (values[count ~/ 2 - 1] + values[count ~/ 2]) / 2
          : values[count ~/ 2],
      'count': count.toDouble(),
    };
  }

  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  void dispose() {
    _streamController.close();
    _history.clear();
    _thresholds.clear();
  }
}

// ============================================================================
// êµ¬ì²´ì ì¸ ë©”íŠ¸ë¦­ êµ¬í˜„
// ============================================================================

/// ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ì¿¼ë¦¬ì‹œê°„, ìºì‹œíˆíŠ¸ìœ¨)
class DatabaseMetrics extends PerformanceMetric {
  static DatabaseMetrics? _instance;
  static DatabaseMetrics get instance => _instance ??= DatabaseMetrics._();

  int _totalQueries = 0;
  int _cacheHits = 0;
  final Map<String, List<Duration>> _queryTimes = {};

  DatabaseMetrics._() : super(name: 'database') {
    // ê¸°ë³¸ ì„ê³„ê°’ ì„¤ì •
    setThreshold(
      MetricThreshold(
        name: 'query_time',
        warningLevel: 100.0, // 100ms
        criticalLevel: 500.0, // 500ms
      ),
    );

    setThreshold(
      MetricThreshold(
        name: 'cache_hit_rate',
        warningLevel: 70.0, // 70%
        criticalLevel: 50.0, // 50%
      ),
    );
  }

  /// ì¿¼ë¦¬ ì‹¤í–‰ ê¸°ë¡
  Future<void> recordQuery(
    String query, {
    required Duration duration,
    bool fromCache = false,
    Map<String, dynamic>? metadata,
  }) async {
    _totalQueries++;
    if (fromCache) _cacheHits++;

    // ì¿¼ë¦¬ ìœ í˜•ë³„ ì‹œê°„ ì¶”ì 
    final queryType = _extractQueryType(query);
    _queryTimes.putIfAbsent(queryType, () => []).add(duration);

    // ì¿¼ë¦¬ ì‹œê°„ ë©”íŠ¸ë¦­
    recordData(
      MetricData(
        metricName: 'database_query_time',
        value: duration.inMilliseconds.toDouble(),
        unit: 'ms',
        metadata: {
          'query_type': queryType,
          'from_cache': fromCache,
          'query': kDebugMode ? query : _sanitizeQuery(query),
          ...?metadata,
        },
      ),
    );

    // ìºì‹œ íˆíŠ¸ìœ¨ ë©”íŠ¸ë¦­
    final hitRate = (_cacheHits / _totalQueries) * 100;
    recordData(
      MetricData(
        metricName: 'database_cache_hit_rate',
        value: hitRate,
        unit: '%',
        metadata: {'total_queries': _totalQueries, 'cache_hits': _cacheHits},
      ),
    );
  }

  /// ì—°ê²° í’€ ë©”íŠ¸ë¦­ ê¸°ë¡
  void recordConnectionPool({
    required int activeConnections,
    required int totalConnections,
    required int waitingRequests,
  }) {
    recordData(
      MetricData(
        metricName: 'database_connection_pool',
        value: (activeConnections / totalConnections) * 100,
        unit: '%',
        metadata: {
          'active_connections': activeConnections,
          'total_connections': totalConnections,
          'waiting_requests': waitingRequests,
          'pool_utilization': (activeConnections / totalConnections) * 100,
        },
      ),
    );
  }

  /// ì¿¼ë¦¬ ìœ í˜• ì¶”ì¶œ
  String _extractQueryType(String query) {
    final normalized = query.trim().toUpperCase();
    if (normalized.startsWith('SELECT')) return 'SELECT';
    if (normalized.startsWith('INSERT')) return 'INSERT';
    if (normalized.startsWith('UPDATE')) return 'UPDATE';
    if (normalized.startsWith('DELETE')) return 'DELETE';
    return 'OTHER';
  }

  /// ì¿¼ë¦¬ ì •ë³´ ì•”í˜¸í™” (ë¯¼ê°í•œ ì •ë³´ ì œê±°)
  String _sanitizeQuery(String query) {
    return query
        .replaceAll(RegExp(r"'[^']*'"), "'***'")
        .replaceAll(RegExp(r'"[^"]*"'), '"***"')
        .replaceAll(RegExp(r'\b\d+\b'), '***');
  }

  /// ì¿¼ë¦¬ í†µê³„ ë¦¬í¬íŠ¸
  Map<String, dynamic> getQueryReport() {
    final report = <String, dynamic>{
      'total_queries': _totalQueries,
      'cache_hits': _cacheHits,
      'cache_hit_rate': _totalQueries > 0
          ? (_cacheHits / _totalQueries) * 100
          : 0.0,
      'query_types': {},
    };

    for (final entry in _queryTimes.entries) {
      final times = entry.value;
      if (times.isNotEmpty) {
        final avgTime =
            times.map((d) => d.inMilliseconds).reduce((a, b) => a + b) /
            times.length;
        report['query_types'][entry.key] = {
          'count': times.length,
          'avg_time_ms': avgTime,
          'min_time_ms': times.map((d) => d.inMilliseconds).reduce(min),
          'max_time_ms': times.map((d) => d.inMilliseconds).reduce(max),
        };
      }
    }

    return report;
  }
}

/// API ì„±ëŠ¥ ë©”íŠ¸ë¦­ (ì‘ë‹µì‹œê°„, ì—ëŸ¬ìœ¨)
class APIMetrics extends PerformanceMetric {
  static APIMetrics? _instance;
  static APIMetrics get instance => _instance ??= APIMetrics._();

  int _totalRequests = 0;
  int _errorRequests = 0;
  final Map<String, List<Duration>> _endpointTimes = {};
  final Map<int, int> _statusCodes = {};

  APIMetrics._() : super(name: 'api') {
    // ê¸°ë³¸ ì„ê³„ê°’ ì„¤ì •
    setThreshold(
      MetricThreshold(
        name: 'response_time',
        warningLevel: 1000.0, // 1ì´ˆ
        criticalLevel: 3000.0, // 3ì´ˆ
      ),
    );

    setThreshold(
      MetricThreshold(
        name: 'error_rate',
        warningLevel: 5.0, // 5%
        criticalLevel: 10.0, // 10%
      ),
    );
  }

  /// API ìš”ì²­ ê¸°ë¡
  Future<void> recordRequest(
    String endpoint, {
    required int statusCode,
    required Duration duration,
    String method = 'GET',
    int? requestSize,
    int? responseSize,
    Map<String, dynamic>? metadata,
  }) async {
    _totalRequests++;
    if (statusCode >= 400) _errorRequests++;

    // ì—”ë“œí¬ì¸íŠ¸ë³„ ì‘ë‹µ ì‹œê°„ ì¶”ì 
    _endpointTimes.putIfAbsent(endpoint, () => []).add(duration);
    _statusCodes[statusCode] = (_statusCodes[statusCode] ?? 0) + 1;

    // ì‘ë‹µ ì‹œê°„ ë©”íŠ¸ë¦­
    recordData(
      MetricData(
        metricName: 'api_response_time',
        value: duration.inMilliseconds.toDouble(),
        unit: 'ms',
        metadata: {
          'endpoint': endpoint,
          'method': method,
          'status_code': statusCode,
          'request_size': requestSize,
          'response_size': responseSize,
          'is_error': statusCode >= 400,
          ...?metadata,
        },
      ),
    );

    // ì—ëŸ¬ìœ¨ ë©”íŠ¸ë¦­
    final errorRate = (_errorRequests / _totalRequests) * 100;
    recordData(
      MetricData(
        metricName: 'api_error_rate',
        value: errorRate,
        unit: '%',
        metadata: {
          'total_requests': _totalRequests,
          'error_requests': _errorRequests,
          'status_codes': Map.from(_statusCodes),
        },
      ),
    );

    // ì²˜ë¦¬ëŸ‰ ë©”íŠ¸ë¦­ (RPS - Requests Per Second)
    _recordThroughput();
  }

  /// ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë©”íŠ¸ë¦­ ê¸°ë¡
  void recordNetworkLatency(Duration latency, String host) {
    recordData(
      MetricData(
        metricName: 'api_network_latency',
        value: latency.inMilliseconds.toDouble(),
        unit: 'ms',
        metadata: {
          'host': host,
          'measurement_time': DateTime.now().toIso8601String(),
        },
      ),
    );
  }

  /// ì²˜ë¦¬ëŸ‰ ê³„ì‚° ë° ê¸°ë¡
  void _recordThroughput() {
    final now = DateTime.now();
    final oneMinuteAgo = now.subtract(const Duration(minutes: 1));

    final recentRequests = history
        .where(
          (data) =>
              data.metricName == 'api_response_time' &&
              data.timestamp.isAfter(oneMinuteAgo),
        )
        .length;

    recordData(
      MetricData(
        metricName: 'api_throughput',
        value: recentRequests / 60.0, // RPS
        unit: 'rps',
        metadata: {
          'measurement_window': '1_minute',
          'total_requests_in_window': recentRequests,
        },
      ),
    );
  }

  /// API í†µê³„ ë¦¬í¬íŠ¸
  Map<String, dynamic> getAPIReport() {
    final report = <String, dynamic>{
      'total_requests': _totalRequests,
      'error_requests': _errorRequests,
      'error_rate': _totalRequests > 0
          ? (_errorRequests / _totalRequests) * 100
          : 0.0,
      'status_codes': Map.from(_statusCodes),
      'endpoints': {},
    };

    for (final entry in _endpointTimes.entries) {
      final times = entry.value;
      if (times.isNotEmpty) {
        final avgTime =
            times.map((d) => d.inMilliseconds).reduce((a, b) => a + b) /
            times.length;
        report['endpoints'][entry.key] = {
          'request_count': times.length,
          'avg_response_time_ms': avgTime,
          'min_response_time_ms': times
              .map((d) => d.inMilliseconds)
              .reduce(min),
          'max_response_time_ms': times
              .map((d) => d.inMilliseconds)
              .reduce(max),
        };
      }
    }

    return report;
  }
}

/// UI ì„±ëŠ¥ ë©”íŠ¸ë¦­ (FPS, ë¹Œë“œì‹œê°„)
class UIMetrics extends PerformanceMetric {
  static UIMetrics? _instance;
  static UIMetrics get instance => _instance ??= UIMetrics._();

  bool _isMonitoring = false;
  final List<Duration> _frameTimes = [];
  final List<Duration> _buildTimes = [];
  Timer? _frameTimer;

  UIMetrics._() : super(name: 'ui') {
    // ê¸°ë³¸ ì„ê³„ê°’ ì„¤ì •
    setThreshold(
      MetricThreshold(
        name: 'fps',
        warningLevel: 55.0, // 55 FPS
        criticalLevel: 30.0, // 30 FPS (ë” ê´€ëŒ€í•œ ì„ê³„ê°’)
      ),
    );

    setThreshold(
      MetricThreshold(
        name: 'build_time',
        warningLevel: 25.0, // 25ms (40fps)
        criticalLevel: 50.0, // 50ms (20fps)
      ),
    );
  }

  /// UI ëª¨ë‹ˆí„°ë§ ì‹œì‘
  void startMonitoring() {
    if (_isMonitoring) return;
    _isMonitoring = true;

    // Frame callback ë“±ë¡
    SchedulerBinding.instance.addTimingsCallback(_onFrameMetrics);

    // ì£¼ê¸°ì  FPS ê³„ì‚°
    _frameTimer = Timer.periodic(const Duration(seconds: 1), (_) {
      _calculateFPS();
    });

    // ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
    _startMemoryMonitoring();
  }

  /// UI ëª¨ë‹ˆí„°ë§ ì¤‘ì§€
  void stopMonitoring() {
    if (!_isMonitoring) return;
    _isMonitoring = false;

    SchedulerBinding.instance.removeTimingsCallback(_onFrameMetrics);
    _frameTimer?.cancel();
    _frameTimer = null;
  }

  /// í”„ë ˆì„ ë©”íŠ¸ë¦­ ì½œë°±
  void _onFrameMetrics(List<FrameTiming> timings) {
    for (final timing in timings) {
      final buildDuration = timing.buildDuration;
      final rasterDuration = timing.rasterDuration;
      final totalDuration = buildDuration + rasterDuration;

      _frameTimes.add(totalDuration);
      _buildTimes.add(buildDuration);

      // íˆìŠ¤í† ë¦¬ í¬ê¸° ê´€ë¦¬
      if (_frameTimes.length > 60) _frameTimes.removeAt(0);
      if (_buildTimes.length > 60) _buildTimes.removeAt(0);

      // ë¹Œë“œ ì‹œê°„ ë©”íŠ¸ë¦­ ê¸°ë¡
      recordData(
        MetricData(
          metricName: 'ui_build_time',
          value: buildDuration.inMicroseconds / 1000.0, // msë¡œ ë³€í™˜
          unit: 'ms',
          metadata: {
            'raster_time_ms': rasterDuration.inMicroseconds / 1000.0,
            'total_frame_time_ms': totalDuration.inMicroseconds / 1000.0,
            'vsync_overhead': timing.vsyncOverhead.inMicroseconds / 1000.0,
          },
        ),
      );
    }
  }

  /// FPS ê³„ì‚° ë° ê¸°ë¡
  void _calculateFPS() {
    if (_frameTimes.isEmpty) return;

    final now = DateTime.now();
    now.subtract(const Duration(seconds: 1));

    // ìµœê·¼ 1ì´ˆê°„ì˜ í”„ë ˆì„ ìˆ˜ ê³„ì‚°
    var recentFrameCount = 0;
    for (int i = _frameTimes.length - 1; i >= 0; i--) {
      final frameAge = now.difference(now.subtract(_frameTimes[i]));
      if (frameAge <= const Duration(seconds: 1)) {
        recentFrameCount++;
      } else {
        break;
      }
    }

    final fps = recentFrameCount.toDouble();
    recordData(
      MetricData(
        metricName: 'ui_fps',
        value: fps,
        unit: 'fps',
        metadata: {
          'frame_count_last_second': recentFrameCount,
          'avg_frame_time_ms': _frameTimes.isNotEmpty
              ? _frameTimes
                        .map((d) => d.inMicroseconds / 1000.0)
                        .reduce((a, b) => a + b) /
                    _frameTimes.length
              : 0.0,
        },
      ),
    );
  }

  /// ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
  void _startMemoryMonitoring() {
    Timer.periodic(const Duration(seconds: 10), (_) {
      if (!_isMonitoring) return;

      // Flutter ë©”ëª¨ë¦¬ ì •ë³´ëŠ” ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ ì •í™•í•¨
      if (kDebugMode) {
        final info = WidgetsBinding.instance.platformDispatcher.implicitView;
        recordData(
          MetricData(
            metricName: 'ui_memory_usage',
            value: 0.0, // ì‹¤ì œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì€ platform-specific êµ¬í˜„ í•„ìš”
            unit: 'MB',
            metadata: {
              'device_pixel_ratio': info?.devicePixelRatio ?? 1.0,
              'physical_size': {
                'width': info?.physicalSize.width ?? 0,
                'height': info?.physicalSize.height ?? 0,
              },
            },
          ),
        );
      }
    });
  }

  /// ìœ„ì ¯ ë¹Œë“œ ì‹œê°„ ìˆ˜ë™ ê¸°ë¡
  void recordBuildTime(String widgetName, Duration buildTime) {
    recordData(
      MetricData(
        metricName: 'ui_widget_build_time',
        value: buildTime.inMicroseconds / 1000.0,
        unit: 'ms',
        metadata: {
          'widget_name': widgetName,
          'build_timestamp': DateTime.now().toIso8601String(),
        },
      ),
    );
  }

  /// ìŠ¤í¬ë¡¤ ì„±ëŠ¥ ê¸°ë¡
  void recordScrollPerformance({
    required double scrollDelta,
    required Duration frameTime,
    bool isJanky = false,
  }) {
    recordData(
      MetricData(
        metricName: 'ui_scroll_performance',
        value: frameTime.inMicroseconds / 1000.0,
        unit: 'ms',
        metadata: {
          'scroll_delta': scrollDelta,
          'is_janky': isJanky,
          'frame_budget_exceeded': frameTime.inMilliseconds > 16,
        },
      ),
    );
  }

  /// UI í†µê³„ ë¦¬í¬íŠ¸
  Map<String, dynamic> getUIReport() {
    final avgFPS = _frameTimes.isNotEmpty
        ? 1000.0 /
              (_frameTimes
                      .map((d) => d.inMicroseconds / 1000.0)
                      .reduce((a, b) => a + b) /
                  _frameTimes.length)
        : 0.0;

    final avgBuildTime = _buildTimes.isNotEmpty
        ? _buildTimes
                  .map((d) => d.inMicroseconds / 1000.0)
                  .reduce((a, b) => a + b) /
              _buildTimes.length
        : 0.0;

    return {
      'is_monitoring': _isMonitoring,
      'avg_fps': avgFPS,
      'avg_build_time_ms': avgBuildTime,
      'frame_budget_misses': _buildTimes
          .where((d) => d.inMilliseconds > 16)
          .length,
      'janky_frame_percentage': _buildTimes.isNotEmpty
          ? (_buildTimes.where((d) => d.inMilliseconds > 16).length /
                    _buildTimes.length) *
                100
          : 0.0,
    };
  }

  @override
  void dispose() {
    stopMonitoring();
    super.dispose();
  }
}

// ============================================================================
// ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° (ì‹±ê¸€í†¤ + Observer íŒ¨í„´)
// ============================================================================

/// ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ê¸° - í†µí•©ëœ Observer + CircularBuffer íŒ¨í„´
class MetricCollector with WidgetsBindingObserver {
  static MetricCollector? _instance;
  static MetricCollector get instance => _instance ??= MetricCollector._();

  final List<PerformanceObserver> _observers = [];
  final Map<String, PerformanceMetric> _metrics = {};
  final StreamController<Map<String, dynamic>> _globalStreamController =
      StreamController<Map<String, dynamic>>.broadcast();

  // Task 8.11: CircularBuffer for memory-efficient storage
  static const int _maxMetricsCount = 1000;
  static const int _batchTransmissionInterval = 5; // 5ë¶„
  static const double _samplingRate = 0.1; // 10% ìƒ˜í”Œë§

  late final CircularBuffer<MetricDataPoint> _metricsBuffer;
  final Random _random = Random();

  bool _isInitialized = false;
  bool _isCollecting = false;
  Timer? _aggregationTimer;
  Timer? _transmissionTimer;

  MetricCollector._() {
    _metricsBuffer = CircularBuffer<MetricDataPoint>(_maxMetricsCount);
  }

  /// ê¸€ë¡œë²Œ ë©”íŠ¸ë¦­ ìŠ¤íŠ¸ë¦¼
  Stream<Map<String, dynamic>> get globalStream =>
      _globalStreamController.stream;

  /// ì´ˆê¸°í™”
  Future<void> initialize() async {
    if (_isInitialized) return;

    try {
      // ê¸°ë³¸ ë©”íŠ¸ë¦­ ë“±ë¡
      registerMetric(DatabaseMetrics.instance);
      registerMetric(APIMetrics.instance);
      registerMetric(UIMetrics.instance);

      // UI ê´€ì°°ìë¡œ ë“±ë¡
      WidgetsBinding.instance.addObserver(this);

      // UI ëª¨ë‹ˆí„°ë§ ì‹œì‘
      UIMetrics.instance.startMonitoring();

      // ì£¼ê¸°ì  ì§‘ê³„ ë° ë°°ì¹˜ ì „ì†¡ ì‹œì‘
      _startAggregation();
      _startBatchTransmission();

      _isInitialized = true;
      _isCollecting = true;
      debugPrint(
        'MetricCollector initialized with CircularBuffer ($_maxMetricsCount capacity)',
      );
    } catch (e) {
      debugPrint('Failed to initialize MetricCollector: $e');
    }
  }

  /// Task 8.11: Start collecting metrics
  void startCollection() {
    if (!_isInitialized) return;
    _isCollecting = true;
    debugPrint('Metrics collection started');
  }

  /// Task 8.11: Stop collecting metrics
  void stopCollection() {
    _isCollecting = false;
    debugPrint('Metrics collection stopped');
  }

  /// Task 8.11: Record metric with sampling
  void recordMetricData(MetricDataPoint metric) {
    if (!_isCollecting || !_shouldSample()) return;

    try {
      _metricsBuffer.add(metric);

      // ê¸€ë¡œë²Œ ìŠ¤íŠ¸ë¦¼ì—ë„ ì „ì†¡ (ê¸°ì¡´ Observer íŒ¨í„´ ìœ ì§€)
      _globalStreamController.add({
        'type': 'metric_recorded',
        'data': metric.toJson(),
        'timestamp': DateTime.now().toIso8601String(),
      });
    } catch (e) {
      debugPrint('Failed to record metric: $e');
    }
  }

  /// Task 8.11: Check if we should sample this metric
  bool _shouldSample() => _random.nextDouble() < _samplingRate;

  /// ê´€ì°°ì ì¶”ê°€
  void addObserver(PerformanceObserver observer) {
    if (!_observers.contains(observer)) {
      _observers.add(observer);
    }
  }

  /// ê´€ì°°ì ì œê±°
  void removeObserver(PerformanceObserver observer) {
    _observers.remove(observer);
  }

  /// ë©”íŠ¸ë¦­ ë“±ë¡
  void registerMetric(PerformanceMetric metric) {
    _metrics[metric.name] = metric;

    // ë©”íŠ¸ë¦­ ìŠ¤íŠ¸ë¦¼ êµ¬ë…
    metric.stream.listen((data) {
      _globalStreamController.add({
        'metric_type': metric.name,
        'data': data.toJson(),
        'timestamp': DateTime.now().toIso8601String(),
      });
    });
  }

  /// ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
  T? getMetric<T extends PerformanceMetric>(String name) {
    return _metrics[name] as T?;
  }

  /// ëª¨ë“  ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
  Map<String, PerformanceMetric> get allMetrics => Map.unmodifiable(_metrics);

  /// ê´€ì°°ìë“¤ì—ê²Œ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ì•Œë¦¼
  void _notifyObservers(PerformanceMetric metric, MetricData data) {
    for (final observer in _observers) {
      try {
        observer.onMetricUpdated(metric, data);
      } catch (e, stackTrace) {
        debugPrint('Observer notification error: $e');
        observer.onError(metric, e.toString(), stackTrace);
      }
    }
  }

  /// ê´€ì°°ìë“¤ì—ê²Œ ì„ê³„ê°’ ì´ˆê³¼ ì•Œë¦¼
  void _notifyThresholdExceeded(
    PerformanceMetric metric,
    MetricData data,
    MetricThreshold threshold,
  ) {
    for (final observer in _observers) {
      try {
        observer.onThresholdExceeded(metric, data, threshold);
      } catch (e, stackTrace) {
        debugPrint('Threshold notification error: $e');
        observer.onError(metric, e.toString(), stackTrace);
      }
    }
  }

  /// Task 8.11: Start batch transmission
  void _startBatchTransmission() {
    _transmissionTimer = Timer.periodic(
      Duration(minutes: _batchTransmissionInterval),
      (_) => _transmitMetrics(),
    );
  }

  /// Task 8.11: Transmit metrics to Vercel Analytics
  Future<void> _transmitMetrics() async {
    if (_metricsBuffer.isEmpty) return;

    try {
      final metrics = _metricsBuffer.toList();
      await _sendToVercelAnalytics(metrics);
      _metricsBuffer.clear();
      debugPrint('Transmitted ${metrics.length} metrics to Vercel Analytics');
    } catch (e) {
      debugPrint('Failed to transmit metrics: $e');
    }
  }

  /// ì£¼ê¸°ì  ë°ì´í„° ì§‘ê³„
  void _startAggregation() {
    _aggregationTimer = Timer.periodic(const Duration(minutes: 1), (_) {
      _performAggregation();
    });
  }

  /// ë°ì´í„° ì§‘ê³„ ìˆ˜í–‰
  void _performAggregation() {
    final aggregatedData = <String, dynamic>{
      'timestamp': DateTime.now().toIso8601String(),
      'metrics': {},
    };

    for (final entry in _metrics.entries) {
      final metric = entry.value;
      final stats = metric.getStatistics(period: const Duration(minutes: 5));

      aggregatedData['metrics'][entry.key] = {
        'statistics': stats,
        'latest_value': metric.latest?.value,
        'data_points': metric.history.length,
      };
    }

    _globalStreamController.add({
      'type': 'aggregation',
      'data': aggregatedData,
    });
  }

  /// ì„±ëŠ¥ ìŠ¤ëƒ…ìƒ· ìƒì„±
  Map<String, dynamic> createSnapshot() {
    final snapshot = <String, dynamic>{
      'timestamp': DateTime.now().toIso8601String(),
      'system_info': _getSystemInfo(),
      'metrics': {},
    };

    for (final entry in _metrics.entries) {
      final metric = entry.value;
      snapshot['metrics'][entry.key] = {
        'latest': metric.latest?.toJson(),
        'statistics': metric.getStatistics(),
        'thresholds': metric.thresholds.map((k, v) => MapEntry(k, v.toJson())),
      };
    }

    return snapshot;
  }

  /// ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
  Map<String, dynamic> _getSystemInfo() {
    return {
      'platform': Platform.operatingSystem,
      'version': Platform.operatingSystemVersion,
      'dart_version': Platform.version,
      'memory_mb': _getMemoryUsage(),
      'timestamp': DateTime.now().toIso8601String(),
    };
  }

  /// ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ì¶”ì •ì¹˜)
  double _getMemoryUsage() {
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” platform-specific ì½”ë“œê°€ í•„ìš”
    return 0.0;
  }

  /// Task 8.11: WidgetsBindingObserver êµ¬í˜„ (UI ìƒëª…ì£¼ê¸° ì¶”ì )
  @override
  void didChangeAppLifecycleState(AppLifecycleState state) {
    super.didChangeAppLifecycleState(state);
    recordMetricData(
      MetricDataPoint(
        type: MetricType.ui,
        name: 'app_lifecycle_change',
        value: 0,
        metadata: {
          'state': state.toString(),
          'timestamp': DateTime.now().millisecondsSinceEpoch,
        },
        timestamp: DateTime.now(),
      ),
    );
  }

  @override
  void didChangeMetrics() {
    super.didChangeMetrics();
    recordMetricData(
      MetricDataPoint(
        type: MetricType.ui,
        name: 'metrics_changed',
        value: 0,
        metadata: {'timestamp': DateTime.now().millisecondsSinceEpoch},
        timestamp: DateTime.now(),
      ),
    );
  }

  /// Task 8.11: Send metrics to Vercel Analytics
  Future<void> _sendToVercelAnalytics(List<MetricDataPoint> metrics) async {
    if (metrics.isEmpty) return;

    try {
      final payload = _prepareVercelPayload(metrics);

      final response = await http.post(
        Uri.parse('https://vitals.vercel-analytics.com/v1/vitals'),
        headers: {
          'Content-Type': 'application/json',
          'User-Agent': 'InsightFlo-Mobile/1.0',
        },
        body: jsonEncode(payload),
      );

      if (response.statusCode != 200) {
        debugPrint('Vercel Analytics error: ${response.statusCode}');
      }
    } catch (e) {
      debugPrint('Failed to send metrics to Vercel Analytics: $e');
    }
  }

  Map<String, dynamic> _prepareVercelPayload(List<MetricDataPoint> metrics) {
    final groupedMetrics = <String, List<MetricDataPoint>>{};

    for (final metric in metrics) {
      final key = metric.type.toString().split('.').last;
      groupedMetrics.putIfAbsent(key, () => []).add(metric);
    }

    return {
      'timestamp': DateTime.now().toIso8601String(),
      'metrics': groupedMetrics.map((type, metricsList) {
        return MapEntry(type, metricsList.map((m) => m.toJson()).toList());
      }),
      'metadata': {
        'app_version': '1.0.0',
        'platform': Platform.operatingSystem,
        'count': metrics.length,
      },
    };
  }

  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  void dispose() {
    _isCollecting = false;
    _aggregationTimer?.cancel();
    _transmissionTimer?.cancel();
    WidgetsBinding.instance.removeObserver(this);
    _globalStreamController.close();
    UIMetrics.instance.stopMonitoring();

    for (final metric in _metrics.values) {
      metric.dispose();
    }

    _metricsBuffer.clear();
    _metrics.clear();
    _observers.clear();
    _isInitialized = false;
  }
}

// ============================================================================
// ì„ê³„ê°’ ì•Œë¦¼ ì‹œìŠ¤í…œ
// ============================================================================

/// ì„ê³„ê°’ ì•Œë¦¼ ê´€ë¦¬ì
class ThresholdAlert {
  static ThresholdAlert? _instance;
  static ThresholdAlert get instance => _instance ??= ThresholdAlert._();

  final Map<String, DateTime> _lastAlertTimes = {};
  final Duration _cooldownPeriod = const Duration(minutes: 5);
  final StreamController<AlertEvent> _alertStreamController =
      StreamController<AlertEvent>.broadcast();

  ThresholdAlert._();

  /// ì•Œë¦¼ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼
  Stream<AlertEvent> get alertStream => _alertStreamController.stream;

  /// ì•Œë¦¼ íŠ¸ë¦¬ê±°
  void triggerAlert(
    PerformanceMetric metric,
    MetricData data,
    MetricThreshold threshold,
    AlertSeverity severity,
  ) {
    final alertKey = '${metric.name}_${threshold.name}';
    final now = DateTime.now();

    // ì¿¨ë‹¤ìš´ ê²€ì‚¬
    final lastAlert = _lastAlertTimes[alertKey];
    if (lastAlert != null && now.difference(lastAlert) < _cooldownPeriod) {
      return;
    }

    _lastAlertTimes[alertKey] = now;

    final alertEvent = AlertEvent(
      metric: metric,
      data: data,
      threshold: threshold,
      severity: severity,
      timestamp: now,
      message: _generateAlertMessage(metric, data, threshold, severity),
    );

    _alertStreamController.add(alertEvent);

    // ë¡œê·¸ ì¶œë ¥
    debugPrint('ğŸš¨ [${severity.name.toUpperCase()}] ${alertEvent.message}');

    // Vercel Analyticsì— ì´ë²¤íŠ¸ ì „ì†¡
    VercelAnalyticsIntegration.instance.sendEvent('performance_alert', {
      'metric_name': metric.name,
      'threshold_name': threshold.name,
      'severity': severity.name,
      'value': data.value,
      'warning_level': threshold.warningLevel,
      'critical_level': threshold.criticalLevel,
    });
  }

  /// ì•Œë¦¼ ë©”ì‹œì§€ ìƒì„±
  String _generateAlertMessage(
    PerformanceMetric metric,
    MetricData data,
    MetricThreshold threshold,
    AlertSeverity severity,
  ) {
    final value = data.value.toStringAsFixed(2);
    final unit = data.unit ?? '';
    final level = severity == AlertSeverity.critical
        ? threshold.criticalLevel
        : threshold.warningLevel;

    return '${metric.name.toUpperCase()} ${threshold.name}: $value$unit '
        '(threshold: ${level.toStringAsFixed(2)}$unit)';
  }

  /// ì•Œë¦¼ íˆìŠ¤í† ë¦¬ ì •ë¦¬
  void clearHistory() {
    _lastAlertTimes.clear();
  }

  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  void dispose() {
    _alertStreamController.close();
    _lastAlertTimes.clear();
  }
}

/// ì•Œë¦¼ ì´ë²¤íŠ¸
class AlertEvent {
  final PerformanceMetric metric;
  final MetricData data;
  final MetricThreshold threshold;
  final AlertSeverity severity;
  final DateTime timestamp;
  final String message;

  AlertEvent({
    required this.metric,
    required this.data,
    required this.threshold,
    required this.severity,
    required this.timestamp,
    required this.message,
  });

  Map<String, dynamic> toJson() => {
    'metric_name': metric.name,
    'data': data.toJson(),
    'threshold': threshold.toJson(),
    'severity': severity.name,
    'timestamp': timestamp.toIso8601String(),
    'message': message,
  };
}

// ============================================================================
// Vercel Analytics í†µí•©
// ============================================================================

/// Vercel Analytics ì»¤ìŠ¤í…€ ì´ë²¤íŠ¸ í†µí•©
class VercelAnalyticsIntegration {
  static VercelAnalyticsIntegration? _instance;
  static VercelAnalyticsIntegration get instance =>
      _instance ??= VercelAnalyticsIntegration._();

  final String _endpoint = 'https://vitals.vercel-analytics.com/v1/vitals';
  final List<Map<String, dynamic>> _pendingEvents = [];
  Timer? _batchTimer;
  bool _isEnabled = true;

  VercelAnalyticsIntegration._() {
    _startBatchProcessing();
  }

  /// Analytics í™œì„±í™”/ë¹„í™œì„±í™”
  void setEnabled(bool enabled) {
    _isEnabled = enabled;
  }

  /// ì»¤ìŠ¤í…€ ì´ë²¤íŠ¸ ì „ì†¡
  Future<void> sendEvent(
    String eventName,
    Map<String, dynamic> properties,
  ) async {
    if (!_isEnabled) return;

    final event = {
      'name': eventName,
      'value': 1,
      'timestamp': DateTime.now().millisecondsSinceEpoch,
      'properties': properties,
    };

    _pendingEvents.add(event);

    // ì„ê³„ ì´ë²¤íŠ¸ëŠ” ì¦‰ì‹œ ì „ì†¡
    if (eventName == 'performance_alert' &&
        properties['severity'] == 'critical') {
      await _sendBatch([event]);
      _pendingEvents.remove(event);
    }
  }

  /// ì„±ëŠ¥ ë°”ì´íƒˆ ì „ì†¡
  Future<void> sendVitals({
    required double cls, // Cumulative Layout Shift
    required double fcp, // First Contentful Paint
    required double fid, // First Input Delay
    required double lcp, // Largest Contentful Paint
    required double ttfb, // Time to First Byte
  }) async {
    if (!_isEnabled) return;

    await sendEvent('web_vitals', {
      'cls': cls,
      'fcp': fcp,
      'fid': fid,
      'lcp': lcp,
      'ttfb': ttfb,
      'url': 'mobile_app', // ëª¨ë°”ì¼ ì•± ì‹ë³„ì
      'user_agent': Platform.operatingSystem,
    });
  }

  /// ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘
  void _startBatchProcessing() {
    _batchTimer = Timer.periodic(const Duration(seconds: 30), (_) {
      if (_pendingEvents.isNotEmpty) {
        _sendBatch(List.from(_pendingEvents));
        _pendingEvents.clear();
      }
    });
  }

  /// ì´ë²¤íŠ¸ ë°°ì¹˜ ì „ì†¡
  Future<void> _sendBatch(List<Map<String, dynamic>> events) async {
    if (events.isEmpty) return;

    try {
      final response = await http.post(
        Uri.parse(_endpoint),
        headers: {
          'Content-Type': 'application/json',
          'User-Agent': 'InsightFlo-Mobile/1.0',
        },
        body: jsonEncode({
          'events': events,
          'dsn': 'mobile_app_vitals', // í”„ë¡œì íŠ¸ë³„ ì‹ë³„ì
        }),
      );

      if (response.statusCode != 200) {
        debugPrint('Vercel Analytics error: ${response.statusCode}');
      }
    } catch (e) {
      debugPrint('Vercel Analytics send error: $e');
    }
  }

  /// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
  void dispose() {
    _batchTimer?.cancel();
    _pendingEvents.clear();
  }
}

// ============================================================================
// ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±ê¸°
// ============================================================================

/// ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±ê¸°
class PerformanceReport {
  static PerformanceReport? _instance;
  static PerformanceReport get instance => _instance ??= PerformanceReport._();

  PerformanceReport._();

  /// ì¢…í•© ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±
  Future<Map<String, dynamic>> generateReport({
    Duration period = const Duration(hours: 24),
    bool includeRawData = false,
  }) async {
    final endTime = DateTime.now();
    final startTime = endTime.subtract(period);

    final report = <String, dynamic>{
      'report_metadata': {
        'generated_at': endTime.toIso8601String(),
        'period_start': startTime.toIso8601String(),
        'period_end': endTime.toIso8601String(),
        'period_hours': period.inHours,
      },
      'summary': {},
      'metrics': {},
      'alerts': {},
      'recommendations': [],
    };

    // ë©”íŠ¸ë¦­ë³„ ë¦¬í¬íŠ¸ ìƒì„±
    final collector = MetricCollector.instance;

    // ë°ì´í„°ë² ì´ìŠ¤ ë©”íŠ¸ë¦­
    final dbMetrics = collector.getMetric<DatabaseMetrics>('database');
    if (dbMetrics != null) {
      report['metrics']['database'] = await _generateDatabaseReport(
        dbMetrics,
        period,
      );
    }

    // API ë©”íŠ¸ë¦­
    final apiMetrics = collector.getMetric<APIMetrics>('api');
    if (apiMetrics != null) {
      report['metrics']['api'] = await _generateAPIReport(apiMetrics, period);
    }

    // UI ë©”íŠ¸ë¦­
    final uiMetrics = collector.getMetric<UIMetrics>('ui');
    if (uiMetrics != null) {
      report['metrics']['ui'] = await _generateUIReport(uiMetrics, period);
    }

    // ìš”ì•½ ìƒì„±
    report['summary'] = _generateSummary(report['metrics']);

    // ê¶Œì¥ì‚¬í•­ ìƒì„±
    report['recommendations'] = _generateRecommendations(report['metrics']);

    // ì•Œë¦¼ í†µê³„
    report['alerts'] = _generateAlertSummary(period);

    return report;
  }

  /// ë°ì´í„°ë² ì´ìŠ¤ ë©”íŠ¸ë¦­ ë¦¬í¬íŠ¸
  Future<Map<String, dynamic>> _generateDatabaseReport(
    DatabaseMetrics metrics,
    Duration period,
  ) async {
    final stats = metrics.getStatistics(period: period);
    final queryReport = metrics.getQueryReport();

    return {
      'statistics': stats,
      'query_analysis': queryReport,
      'performance_grade': _calculateGrade(
        stats['avg'] ?? 0,
        100,
        500,
      ), // 100ms good, 500ms poor
      'trends': _calculateTrends(metrics.history, period),
    };
  }

  /// API ë©”íŠ¸ë¦­ ë¦¬í¬íŠ¸
  Future<Map<String, dynamic>> _generateAPIReport(
    APIMetrics metrics,
    Duration period,
  ) async {
    final stats = metrics.getStatistics(period: period);
    final apiReport = metrics.getAPIReport();

    return {
      'statistics': stats,
      'endpoint_analysis': apiReport,
      'performance_grade': _calculateGrade(
        stats['avg'] ?? 0,
        1000,
        3000,
      ), // 1s good, 3s poor
      'trends': _calculateTrends(metrics.history, period),
    };
  }

  /// UI ë©”íŠ¸ë¦­ ë¦¬í¬íŠ¸
  Future<Map<String, dynamic>> _generateUIReport(
    UIMetrics metrics,
    Duration period,
  ) async {
    final stats = metrics.getStatistics(period: period);
    final uiReport = metrics.getUIReport();

    return {
      'statistics': stats,
      'ui_analysis': uiReport,
      'performance_grade': _calculateGrade(
        60 - (stats['avg'] ?? 0),
        55,
        45,
      ), // 60fps good, 45fps poor
      'trends': _calculateTrends(metrics.history, period),
    };
  }

  /// ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚° (A, B, C, D, F)
  String _calculateGrade(
    double value,
    double goodThreshold,
    double poorThreshold,
  ) {
    if (value <= goodThreshold) return 'A';
    if (value <= goodThreshold * 1.2) return 'B';
    if (value <= poorThreshold * 0.8) return 'C';
    if (value <= poorThreshold) return 'D';
    return 'F';
  }

  /// íŠ¸ë Œë“œ ë¶„ì„
  Map<String, dynamic> _calculateTrends(
    List<MetricData> history,
    Duration period,
  ) {
    final cutoff = DateTime.now().subtract(period);
    final relevantData = history
        .where((d) => d.timestamp.isAfter(cutoff))
        .toList();

    if (relevantData.length < 2) {
      return {'trend': 'insufficient_data', 'change_percent': 0.0};
    }

    final halfPoint = relevantData.length ~/ 2;
    final firstHalf = relevantData.take(halfPoint).map((d) => d.value).toList();
    final secondHalf = relevantData
        .skip(halfPoint)
        .map((d) => d.value)
        .toList();

    final firstAvg = firstHalf.reduce((a, b) => a + b) / firstHalf.length;
    final secondAvg = secondHalf.reduce((a, b) => a + b) / secondHalf.length;

    final changePercent = ((secondAvg - firstAvg) / firstAvg) * 100;

    String trend;
    if (changePercent.abs() < 5) {
      trend = 'stable';
    } else if (changePercent > 0) {
      trend = 'increasing';
    } else {
      trend = 'decreasing';
    }

    return {
      'trend': trend,
      'change_percent': changePercent,
      'first_half_avg': firstAvg,
      'second_half_avg': secondAvg,
    };
  }

  /// ë¦¬í¬íŠ¸ ìš”ì•½ ìƒì„±
  Map<String, dynamic> _generateSummary(Map<String, dynamic> metrics) {
    final grades = <String>[];
    final issues = <String>[];

    for (final entry in metrics.entries) {
      final metricData = entry.value as Map<String, dynamic>;
      final grade = metricData['performance_grade'] as String;
      grades.add(grade);

      if (grade == 'D' || grade == 'F') {
        issues.add('${entry.key} performance needs attention');
      }
    }

    // ì „ì²´ ë“±ê¸‰ ê³„ì‚°
    final gradePoints = grades
        .map(
          (g) => g == 'A'
              ? 4
              : g == 'B'
              ? 3
              : g == 'C'
              ? 2
              : g == 'D'
              ? 1
              : 0,
        )
        .toList();

    final avgGrade = gradePoints.isNotEmpty
        ? gradePoints.reduce((a, b) => a + b) / gradePoints.length
        : 0.0;

    String overallGrade;
    if (avgGrade >= 3.5) {
      overallGrade = 'A';
      // ignore: curly_braces_in_flow_control_structures
    } else if (avgGrade >= 2.5)
      overallGrade = 'B';
    // ignore: curly_braces_in_flow_control_structures
    else if (avgGrade >= 1.5)
      overallGrade = 'C';
    // ignore: curly_braces_in_flow_control_structures
    else if (avgGrade >= 0.5)
      overallGrade = 'D';
    // ignore: curly_braces_in_flow_control_structures
    else
      overallGrade = 'F';

    return {
      'overall_grade': overallGrade,
      'grade_average': avgGrade,
      'critical_issues': issues,
      'metrics_analyzed': metrics.length,
    };
  }

  /// ê¶Œì¥ì‚¬í•­ ìƒì„±
  List<String> _generateRecommendations(Map<String, dynamic> metrics) {
    final recommendations = <String>[];

    // ë°ì´í„°ë² ì´ìŠ¤ ê¶Œì¥ì‚¬í•­
    final dbMetrics = metrics['database'] as Map<String, dynamic>?;
    if (dbMetrics != null) {
      final grade = dbMetrics['performance_grade'] as String;
      if (grade == 'D' || grade == 'F') {
        recommendations.add(
          'Consider optimizing database queries and adding indexes',
        );
        recommendations.add(
          'Review query patterns and implement query caching',
        );
      }
    }

    // API ê¶Œì¥ì‚¬í•­
    final apiMetrics = metrics['api'] as Map<String, dynamic>?;
    if (apiMetrics != null) {
      final grade = apiMetrics['performance_grade'] as String;
      if (grade == 'D' || grade == 'F') {
        recommendations.add('Implement API response caching and compression');
        recommendations.add('Consider using CDN for static content');
      }
    }

    // UI ê¶Œì¥ì‚¬í•­
    final uiMetrics = metrics['ui'] as Map<String, dynamic>?;
    if (uiMetrics != null) {
      final grade = uiMetrics['performance_grade'] as String;
      if (grade == 'D' || grade == 'F') {
        recommendations.add(
          'Optimize widget builds and reduce unnecessary rebuilds',
        );
        recommendations.add('Implement lazy loading for large lists');
      }
    }

    if (recommendations.isEmpty) {
      recommendations.add(
        'Performance is good! Continue monitoring for any degradation',
      );
    }

    return recommendations;
  }

  /// ì•Œë¦¼ ìš”ì•½ ìƒì„±
  Map<String, dynamic> _generateAlertSummary(Duration period) {
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ThresholdAlertì˜ ì´ë²¤íŠ¸ íˆìŠ¤í† ë¦¬ë¥¼ ì‚¬ìš©
    return {
      'total_alerts': 0,
      'critical_alerts': 0,
      'warning_alerts': 0,
      'most_frequent_alert': null,
    };
  }

  /// ë¦¬í¬íŠ¸ë¥¼ JSONìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
  Future<String> exportToJson(Map<String, dynamic> report) async {
    return jsonEncode(report);
  }

  /// ë¦¬í¬íŠ¸ë¥¼ CSVë¡œ ë‚´ë³´ë‚´ê¸° (ë©”íŠ¸ë¦­ ë°ì´í„°)
  Future<String> exportToCSV(Map<String, dynamic> report) async {
    final lines = <String>['Timestamp,Metric,Value,Unit'];

    final metrics = report['metrics'] as Map<String, dynamic>;
    for (final entry in metrics.entries) {
      final metricData = entry.value as Map<String, dynamic>;
      final stats = metricData['statistics'] as Map<String, dynamic>;

      lines.add(
        '${DateTime.now().toIso8601String()},${entry.key}_avg,${stats['avg']},ms',
      );
      lines.add(
        '${DateTime.now().toIso8601String()},${entry.key}_min,${stats['min']},ms',
      );
      lines.add(
        '${DateTime.now().toIso8601String()},${entry.key}_max,${stats['max']},ms',
      );
    }

    return lines.join('\n');
  }
}

// ============================================================================
// Task 8.11: CircularBuffer ë° ë©”íŠ¸ë¦­ ë°ì´í„° í¬ì¸íŠ¸
// ============================================================================

/// Task 8.11: Circular buffer for memory-efficient storage
class CircularBuffer<T> {
  late List<T?> _buffer;
  int _head = 0;
  int _tail = 0;
  int _size = 0;
  final int _capacity;

  CircularBuffer(this._capacity) {
    _buffer = List<T?>.filled(_capacity, null);
  }

  void add(T item) {
    _buffer[_tail] = item;
    _tail = (_tail + 1) % _capacity;

    if (_size < _capacity) {
      _size++;
    } else {
      _head = (_head + 1) % _capacity;
    }
  }

  List<T> toList() {
    final result = <T>[];
    for (int i = 0; i < _size; i++) {
      final index = (_head + i) % _capacity;
      final item = _buffer[index];
      if (item != null) result.add(item);
    }
    return result;
  }

  void clear() {
    _head = 0;
    _tail = 0;
    _size = 0;
    _buffer.fillRange(0, _capacity, null);
  }

  bool get isEmpty => _size == 0;
  bool get isFull => _size == _capacity;
  int get length => _size;
}

/// Task 8.11: Simplified metric data point for CircularBuffer
class MetricDataPoint {
  final MetricType type;
  final String name;
  final double value;
  final Map<String, dynamic> metadata;
  final DateTime timestamp;

  MetricDataPoint({
    required this.type,
    required this.name,
    required this.value,
    required this.metadata,
    required this.timestamp,
  });

  Map<String, dynamic> toJson() {
    return {
      'type': type.toString().split('.').last,
      'name': name,
      'value': value,
      'metadata': metadata,
      'timestamp': timestamp.toIso8601String(),
    };
  }

  @override
  String toString() {
    return 'MetricDataPoint(type: $type, name: $name, value: $value)';
  }
}

/// Task 8.11: Metric types for simplified collection
enum MetricType { database, api, ui, memory, startup }

// ============================================================================
// ì‚¬ìš© ì˜ˆì œ ë° ë„ìš°ë¯¸ í´ë˜ìŠ¤
// ============================================================================

/// ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë„ìš°ë¯¸ í´ë˜ìŠ¤
class PerformanceHelper {
  /// í•¨ìˆ˜ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
  static Future<T> measureExecutionTime<T>(
    String operationName,
    Future<T> Function() operation, {
    String category = 'general',
  }) async {
    final stopwatch = Stopwatch()..start();

    try {
      final result = await operation();
      stopwatch.stop();

      // ë©”íŠ¸ë¦­ ê¸°ë¡
      MetricCollector.instance
          .getMetric<DatabaseMetrics>('database')
          ?.recordData(
            MetricData(
              metricName: 'operation_duration',
              value: stopwatch.elapsedMilliseconds.toDouble(),
              unit: 'ms',
              metadata: {
                'operation_name': operationName,
                'category': category,
                'success': true,
              },
            ),
          );

      return result;
    } catch (e) {
      stopwatch.stop();

      // ì—ëŸ¬ ë©”íŠ¸ë¦­ ê¸°ë¡
      MetricCollector.instance
          .getMetric<DatabaseMetrics>('database')
          ?.recordData(
            MetricData(
              metricName: 'operation_duration',
              value: stopwatch.elapsedMilliseconds.toDouble(),
              unit: 'ms',
              metadata: {
                'operation_name': operationName,
                'category': category,
                'success': false,
                'error': e.toString(),
              },
            ),
          );

      rethrow;
    }
  }

  /// ìœ„ì ¯ ë¹Œë“œ ì‹œê°„ ì¸¡ì • ë°ì½”ë ˆì´í„°
  static Widget measureBuildTime(String widgetName, Widget Function() builder) {
    return Builder(
      builder: (context) {
        final stopwatch = Stopwatch()..start();
        final widget = builder();
        stopwatch.stop();

        WidgetsBinding.instance.addPostFrameCallback((_) {
          UIMetrics.instance.recordBuildTime(widgetName, stopwatch.elapsed);
        });

        return widget;
      },
    );
  }
}

/// ê¸°ë³¸ ì„±ëŠ¥ ê´€ì°°ì êµ¬í˜„
class DefaultPerformanceObserver implements PerformanceObserver {
  @override
  void onMetricUpdated(PerformanceMetric metric, MetricData data) {
    // ê¸°ë³¸ì ìœ¼ë¡œ ë””ë²„ê·¸ ë¡œê·¸ë§Œ ì¶œë ¥
    if (kDebugMode) {
      debugPrint(
        'ğŸ“Š ${metric.name}: ${data.metricName} = ${data.value}${data.unit ?? ''}',
      );
    }
  }

  @override
  void onThresholdExceeded(
    PerformanceMetric metric,
    MetricData data,
    MetricThreshold threshold,
  ) {
    debugPrint(
      'âš ï¸ Threshold exceeded: ${metric.name}.${threshold.name} = ${data.value}',
    );
  }

  @override
  void onError(PerformanceMetric metric, String error, StackTrace? stackTrace) {
    debugPrint('âŒ Performance monitoring error in ${metric.name}: $error');
    if (stackTrace != null && kDebugMode) {
      debugPrint(stackTrace.toString());
    }
  }
}

// ============================================================================
// Task 8.11: ê°„ì†Œí™”ëœ Extension API
// ============================================================================

/// Task 8.11: Extension methods for easy integration
extension MetricCollectorExtensions on MetricCollector {
  /// Easy database query wrapping
  Future<T> measureDatabaseQuery<T>(
    String queryName,
    Future<T> Function() query, {
    Map<String, dynamic>? metadata,
  }) async {
    final stopwatch = Stopwatch()..start();
    T result;
    String? error;

    try {
      result = await query();
    } catch (e) {
      error = e.toString();
      rethrow;
    } finally {
      stopwatch.stop();

      recordMetricData(
        MetricDataPoint(
          type: MetricType.database,
          name: queryName,
          value: stopwatch.elapsedMilliseconds.toDouble(),
          metadata: {
            'duration_ms': stopwatch.elapsedMilliseconds,
            'error': error,
            ...?metadata,
          },
          timestamp: DateTime.now(),
        ),
      );
    }

    return result;
  }

  /// Easy synchronous database query wrapping
  T measureSyncDatabaseQuery<T>(
    String queryName,
    T Function() query, {
    Map<String, dynamic>? metadata,
  }) {
    final stopwatch = Stopwatch()..start();
    T result;
    String? error;

    try {
      result = query();
    } catch (e) {
      error = e.toString();
      rethrow;
    } finally {
      stopwatch.stop();

      recordMetricData(
        MetricDataPoint(
          type: MetricType.database,
          name: queryName,
          value: stopwatch.elapsedMilliseconds.toDouble(),
          metadata: {
            'duration_ms': stopwatch.elapsedMilliseconds,
            'error': error,
            ...?metadata,
          },
          timestamp: DateTime.now(),
        ),
      );
    }

    return result;
  }

  /// Record custom metric
  void recordCustomMetric({
    required String name,
    required double value,
    MetricType type = MetricType.ui,
    Map<String, dynamic>? metadata,
  }) {
    recordMetricData(
      MetricDataPoint(
        type: type,
        name: name,
        value: value,
        metadata: metadata ?? {},
        timestamp: DateTime.now(),
      ),
    );
  }

  /// Get Dio interceptor for API monitoring
  Interceptor get dioInterceptor {
    return InterceptorsWrapper(
      onRequest: (options, handler) {
        options.extra['start_time'] = DateTime.now().millisecondsSinceEpoch;
        handler.next(options);
      },
      onResponse: (response, handler) {
        _recordAPIMetric(response.requestOptions, response: response);
        handler.next(response);
      },
      onError: (error, handler) {
        _recordAPIMetric(error.requestOptions, error: error);
        handler.next(error);
      },
    );
  }

  void _recordAPIMetric(
    RequestOptions options, {
    Response? response,
    DioException? error,
  }) {
    final startTime = options.extra['start_time'] as int?;
    if (startTime == null) return;

    final endTime = DateTime.now().millisecondsSinceEpoch;
    final duration = endTime - startTime;

    recordMetricData(
      MetricDataPoint(
        type: MetricType.api,
        name: '${options.method} ${options.path}',
        value: duration.toDouble(),
        metadata: {
          'method': options.method,
          'url': options.uri.toString(),
          'duration_ms': duration,
          'status_code': response?.statusCode ?? error?.response?.statusCode,
          'response_size': response?.data?.toString().length ?? 0,
          'error': error?.message,
        },
        timestamp: DateTime.now(),
      ),
    );
  }
}
